{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a7c6d4c",
   "metadata": {
    "id": "3a7c6d4c"
   },
   "source": [
    "# Project Assignment #1: Confidence Intervals and Hypothesis Testing\n",
    "## Team Member:\n",
    "- Alex Magnus\n",
    "- Erkhes Tumurtogoo\n",
    "- Jianyuan Qiu\n",
    "- Rithvik Sunil\n",
    "- Haoliang Zhao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a8b6fe8",
   "metadata": {
    "id": "5a8b6fe8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_indicators = pd.read_csv('country_indicators.csv')\n",
    "df_preds = pd.read_csv('test_predictions.csv')\n",
    "df_merged = df_preds.merge(df_indicators, left_on='iso3', right_on='iso3', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcf203d",
   "metadata": {
    "id": "1dcf203d"
   },
   "source": [
    "## \"Unpaired\" Data\n",
    "- Make sure the sequence of analyses that you perform are clear and understandable. E.g., what model(s) data are used, and for what data subset(s)?\n",
    "\n",
    "    - Your mark for the Tutorial Assignment will be based on completing the items below and the clarity and correctness of your work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7299c8",
   "metadata": {
    "id": "8d7299c8"
   },
   "source": [
    "### 1. Create the Prediciton Probability \"Error\" results for the xgboost and ffnn models analagously to the transformer model produced above. - **Alex**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6a9e49e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "d6a9e49e",
    "outputId": "5989bec9-5848-4a8d-d8f4-4c2d5fad1f34"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true_transformer</th>\n",
       "      <th>y_pred_proba_transformer</th>\n",
       "      <th>transformer_probability_prediction_error</th>\n",
       "      <th>xgboost_probability_prediction_error</th>\n",
       "      <th>ffnn_probability_prediction_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>0.183897</td>\n",
       "      <td>0.183897</td>\n",
       "      <td>0.066500</td>\n",
       "      <td>0.409958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>0.267831</td>\n",
       "      <td>0.267831</td>\n",
       "      <td>0.099643</td>\n",
       "      <td>0.406696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>0.482585</td>\n",
       "      <td>0.482585</td>\n",
       "      <td>0.295914</td>\n",
       "      <td>0.545236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>0.187792</td>\n",
       "      <td>0.187792</td>\n",
       "      <td>0.361556</td>\n",
       "      <td>0.534560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>0.539319</td>\n",
       "      <td>0.460681</td>\n",
       "      <td>0.608380</td>\n",
       "      <td>0.461417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>False</td>\n",
       "      <td>0.182196</td>\n",
       "      <td>0.182196</td>\n",
       "      <td>0.079453</td>\n",
       "      <td>0.291874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>False</td>\n",
       "      <td>0.203236</td>\n",
       "      <td>0.203236</td>\n",
       "      <td>0.060189</td>\n",
       "      <td>0.300321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>False</td>\n",
       "      <td>0.527107</td>\n",
       "      <td>0.527107</td>\n",
       "      <td>0.302375</td>\n",
       "      <td>0.335496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>False</td>\n",
       "      <td>0.555677</td>\n",
       "      <td>0.555677</td>\n",
       "      <td>0.729246</td>\n",
       "      <td>0.324000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>True</td>\n",
       "      <td>0.565700</td>\n",
       "      <td>0.434300</td>\n",
       "      <td>0.591722</td>\n",
       "      <td>0.667545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>364 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_true_transformer  y_pred_proba_transformer  \\\n",
       "0                 False                  0.183897   \n",
       "1                 False                  0.267831   \n",
       "2                 False                  0.482585   \n",
       "3                 False                  0.187792   \n",
       "4                  True                  0.539319   \n",
       "..                  ...                       ...   \n",
       "359               False                  0.182196   \n",
       "360               False                  0.203236   \n",
       "361               False                  0.527107   \n",
       "362               False                  0.555677   \n",
       "363                True                  0.565700   \n",
       "\n",
       "     transformer_probability_prediction_error  \\\n",
       "0                                    0.183897   \n",
       "1                                    0.267831   \n",
       "2                                    0.482585   \n",
       "3                                    0.187792   \n",
       "4                                    0.460681   \n",
       "..                                        ...   \n",
       "359                                  0.182196   \n",
       "360                                  0.203236   \n",
       "361                                  0.527107   \n",
       "362                                  0.555677   \n",
       "363                                  0.434300   \n",
       "\n",
       "     xgboost_probability_prediction_error  ffnn_probability_prediction_error  \n",
       "0                                0.066500                           0.409958  \n",
       "1                                0.099643                           0.406696  \n",
       "2                                0.295914                           0.545236  \n",
       "3                                0.361556                           0.534560  \n",
       "4                                0.608380                           0.461417  \n",
       "..                                    ...                                ...  \n",
       "359                              0.079453                           0.291874  \n",
       "360                              0.060189                           0.300321  \n",
       "361                              0.302375                           0.335496  \n",
       "362                              0.729246                           0.324000  \n",
       "363                              0.591722                           0.667545  \n",
       "\n",
       "[364 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "#TRANSFORMER\n",
    "df_preds['transformer_probability_prediction_error'] = np.abs(df_preds['y_true_transformer'].astype(float) - df_preds['y_pred_proba_transformer'])\n",
    "\n",
    "#XGboost\n",
    "df_preds['xgboost_probability_prediction_error'] = np.abs(df_preds['y_true_xgboost'].astype(float) - df_preds['y_pred_proba_xgboost'])\n",
    "\n",
    "#ffnn\n",
    "df_preds['ffnn_probability_prediction_error'] = np.abs(df_preds['y_true_ffnn'].astype(float) - df_preds['y_pred_proba_ffnn'])\n",
    "\n",
    "df_preds[['y_true_transformer','y_pred_proba_transformer','transformer_probability_prediction_error', 'xgboost_probability_prediction_error', 'ffnn_probability_prediction_error']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812e9650",
   "metadata": {
    "id": "812e9650"
   },
   "source": [
    "### 2. Create a bootsrap confidence interval for the average Prediction Probability \"Error\" for one of these models using all the data. - **Alex**\n",
    "> In this context \"using all the data\" means using all the predictions made for a given model under consideration; whereas, \"using a data subset\" would mean restricting the rows of the data on the basis of one (or more) of the columns from the \"Progress Indicators\" data so as to only consider the predictions made for the given model under consideration within a given subset of (the countries of) the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LD1aS-GNYEQ4",
   "metadata": {
    "id": "LD1aS-GNYEQ4"
   },
   "source": [
    "### Confidence Interval with 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b32208c8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b32208c8",
    "outputId": "6e4cde04-6538-4257-c2a7-f7201c904de6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.42372167, 0.45860283])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reps = 1000\n",
    "average_error_of_transformer = np.zeros(reps)\n",
    "np.random.seed(123)\n",
    "\n",
    "for rep in range(reps):\n",
    "    bootstrap_sample = np.random.choice(df_preds['transformer_probability_prediction_error'], size=df_preds.shape[0])\n",
    "    average_error_of_transformer[rep] = bootstrap_sample.mean()\n",
    "\n",
    "np.quantile(average_error_of_transformer, (0.025, 0.975))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28800478",
   "metadata": {
    "id": "28800478"
   },
   "source": [
    "### 3. Create the Prediction Classification \"Correctness\" results of \"correct\" and \"incorrect\" predictions for the `transformer`, `xgboost` and `ffnn` models; or, an alternative \"either/or\" breakdown of interest (such as \"wrongly predicted no escalation\" versus all the other categories combined). - **Alex**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "EvcSus3L93JJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "EvcSus3L93JJ",
    "outputId": "b819048f-cea4-40b3-85e8-2654c6740728"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true_transformer</th>\n",
       "      <th>y_pred_transformer</th>\n",
       "      <th>transformer_classifcation_performance_outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>364 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_true_transformer  y_pred_transformer  \\\n",
       "0                 False               False   \n",
       "1                 False               False   \n",
       "2                 False               False   \n",
       "3                 False               False   \n",
       "4                  True                True   \n",
       "..                  ...                 ...   \n",
       "359               False               False   \n",
       "360               False               False   \n",
       "361               False                True   \n",
       "362               False                True   \n",
       "363                True                True   \n",
       "\n",
       "    transformer_classifcation_performance_outcome  \n",
       "0               correctly predicted no escalation  \n",
       "1               correctly predicted no escalation  \n",
       "2               correctly predicted no escalation  \n",
       "3               correctly predicted no escalation  \n",
       "4                  correctly predicted escalation  \n",
       "..                                            ...  \n",
       "359             correctly predicted no escalation  \n",
       "360             correctly predicted no escalation  \n",
       "361                  wrongly predicted escalation  \n",
       "362                  wrongly predicted escalation  \n",
       "363                correctly predicted escalation  \n",
       "\n",
       "[364 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction Classification \"Correctness\"\n",
    "\n",
    "threshold_transformer = 0.5\n",
    "threshold_xgboost = 0.5\n",
    "threshold_ffnn = 0.5\n",
    "\n",
    "df_preds['transformer_classifcation_performance_outcome'] = None\n",
    "df_preds['xgboost_classifcation_performance_outcome'] = None\n",
    "df_preds['ffnn_classifcation_performance_outcome'] = None\n",
    "\n",
    "tmp = df_preds['transformer_classifcation_performance_outcome'].copy()\n",
    "#tmp_xgboost = df_preds['xgboost_classifcation_performance_outcome'].copy()\n",
    "#tmp_ffnn = df_preds['ffnn_classifcation_performance_outcome'].copy()\n",
    "\n",
    "#TRANSFORMER\n",
    "TP_pos_pred_correct = df_preds.y_true_transformer & (df_preds.y_pred_proba_transformer>threshold_transformer)\n",
    "tmp[TP_pos_pred_correct] = \"correctly predicted escalation\"\n",
    "TN_neg_pred_correct = (~df_preds.y_true_transformer) & (df_preds.y_pred_proba_transformer<=threshold_transformer)\n",
    "tmp[TN_neg_pred_correct] = \"correctly predicted no escalation\"\n",
    "FP_pos_pred_wrong = (~df_preds.y_true_transformer) & (df_preds.y_pred_proba_transformer>threshold_transformer)\n",
    "tmp[FP_pos_pred_wrong] = \"wrongly predicted escalation\"\n",
    "FN_neg_pred_wrong = df_preds.y_true_transformer & (df_preds.y_pred_proba_transformer<=threshold_transformer)\n",
    "tmp[FN_neg_pred_wrong] = \"wrongly predicted no escalation\"\n",
    "\n",
    "df_preds['transformer_classifcation_performance_outcome'] = tmp\n",
    "\n",
    "#xgboost\n",
    "TP_pos_pred_correct = df_preds.y_true_xgboost & (df_preds.y_pred_proba_xgboost>threshold_xgboost)\n",
    "tmp[TP_pos_pred_correct] = \"correctly predicted escalation\"\n",
    "TN_neg_pred_correct = (~df_preds.y_true_xgboost) & (df_preds.y_pred_proba_xgboost<=threshold_xgboost)\n",
    "tmp[TN_neg_pred_correct] = \"correctly predicted no escalation\"\n",
    "FP_pos_pred_wrong = (~df_preds.y_true_xgboost) & (df_preds.y_pred_proba_xgboost>threshold_xgboost)\n",
    "tmp[FP_pos_pred_wrong] = \"wrongly predicted escalation\"\n",
    "FN_neg_pred_wrong = df_preds.y_true_xgboost & (df_preds.y_pred_proba_xgboost<=threshold_xgboost)\n",
    "tmp[FN_neg_pred_wrong] = \"wrongly predicted no escalation\"\n",
    "\n",
    "df_preds['xgboost_classifcation_performance_outcome'] = tmp\n",
    "\n",
    "#ffnn\n",
    "TP_pos_pred_correct = df_preds.y_true_ffnn & (df_preds.y_pred_proba_ffnn>threshold_ffnn)\n",
    "tmp[TP_pos_pred_correct] = \"correctly predicted escalation\"\n",
    "TN_neg_pred_correct = (~df_preds.y_true_ffnn) & (df_preds.y_pred_proba_ffnn<=threshold_ffnn)\n",
    "tmp[TN_neg_pred_correct] = \"correctly predicted no escalation\"\n",
    "FP_pos_pred_wrong = (~df_preds.y_true_ffnn) & (df_preds.y_pred_proba_ffnn>threshold_ffnn)\n",
    "tmp[FP_pos_pred_wrong] = \"wrongly predicted escalation\"\n",
    "FN_neg_pred_wrong = df_preds.y_true_ffnn & (df_preds.y_pred_proba_ffnn<=threshold_ffnn)\n",
    "tmp[FN_neg_pred_wrong] = \"wrongly predicted no escalation\"\n",
    "\n",
    "df_preds['ffnn_classifcation_performance_outcome'] = tmp\n",
    "\n",
    "df_preds[['y_true_transformer','y_pred_transformer','transformer_classifcation_performance_outcome']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1671086f",
   "metadata": {
    "id": "1671086f"
   },
   "source": [
    "### 4. Perform a one sample hypothesis test of the proportion of a specific Prediction Classification \"Correctness\" category for another of these models using all the data. - **Haoliang**\n",
    "- When performing a hypothesis test you'll need to determine and specify the null hypothesis under consideration; obtain a p-value (either through simulation, or `scipy.stats.binom` or `scipy.stats.ttest_1samp`); and, finally, provide a statement of the degree of evidence against the null hypothesis in the usual manner (of https://www.jcpcarchives.org/userfiles/values-of-p-Inference.jpg)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ce2mkZb1pQDc",
   "metadata": {
    "id": "Ce2mkZb1pQDc"
   },
   "source": [
    "### Null Hypothesis\n",
    "$H_\\text{trans_0}: p_\\text{preds}=p=0.5 (\\text{The proportion of the Transformer Prediction Classification \"Correctness\" category is 0.5})$\n",
    "\n",
    "$H_\\text{xgboo_0}: p_\\text{preds}=p=0.5 (\\text{The proportion of the Xgboost Prediction Classification \"Correctness\" category is 0.5})$\n",
    "\n",
    "$H_\\text{ffnn_0}: p_\\text{preds}=p=0.5 (\\text{The proportion of the FFNN Prediction Classification \"Correctness\" category is 0.5})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "C846ueF6nws4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C846ueF6nws4",
    "outputId": "e5948bb5-a4a0-4ac0-e4ba-6c6d0d4f892c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "null = 0.5\n",
    "rep,n=10000,df_preds.shape[0]\n",
    "\n",
    "# For Transformer\n",
    "observed_test_stat =  \\\n",
    "((df_preds['transformer_classifcation_performance_outcome'] == 'correctly predicted no escalation')\n",
    " | (df_preds['transformer_classifcation_performance_outcome'] == 'correctly predicted escalation')).mean()\n",
    "\n",
    "test_stat = np.zeros(rep)\n",
    "for i in range(rep):\n",
    "    sample_mean = sum(np.random.choice(['Correct', 'Incorrect'], size=n) == 'Correct')/n\n",
    "    test_stat[i] = sample_mean\n",
    "\n",
    "sum(abs(test_stat-null) >= abs(observed_test_stat-null)) / rep # p-value=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7NZAirEvxwwz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7NZAirEvxwwz",
    "outputId": "605e7458-cc3f-42c4-d37a-10958717e3bf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8782"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For Xgboost\n",
    "np.random.seed(123)\n",
    "observed_test_stat =  \\\n",
    "((df_preds['xgboost_classifcation_performance_outcome'] == 'correctly predicted no escalation')\n",
    " | (df_preds['xgboost_classifcation_performance_outcome'] == 'correctly predicted escalation')).mean()\n",
    "\n",
    "test_stat = np.zeros(rep)\n",
    "for i in range(rep):\n",
    "    sample_mean = sum(np.random.choice(['Correct', 'Incorrect'], size=n) == 'Correct')/n\n",
    "    test_stat[i] = sample_mean\n",
    "\n",
    "sum(abs(test_stat-null) >= abs(observed_test_stat-null)) / rep # p-value=0.8839"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8D4ygm4Px9CJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8D4ygm4Px9CJ",
    "outputId": "65449ee6-74ef-4c89-965a-43918740badb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For ffnn\n",
    "np.random.seed(123)\n",
    "observed_test_stat =  \\\n",
    "((df_preds['ffnn_classifcation_performance_outcome'] == 'correctly predicted no escalation')\n",
    " | (df_preds['ffnn_classifcation_performance_outcome'] == 'correctly predicted escalation')).mean()\n",
    "\n",
    "test_stat = np.zeros(rep)\n",
    "for i in range(rep):\n",
    "    sample_mean = sum(np.random.choice(['Correct', 'Incorrect'], size=n) == 'Correct')/n\n",
    "    test_stat[i] = sample_mean\n",
    "\n",
    "sum(abs(test_stat-null) >= abs(observed_test_stat-null)) / rep #p-value=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TuO3E7MWhgv8",
   "metadata": {
    "id": "TuO3E7MWhgv8"
   },
   "source": [
    "### Conclusion:\n",
    "By comparing the p-value to the table, We conclude that there is strong evidence against our null hypothesis of Transformer and FFNN since the p-values for both of them are 0. Still, on the other hand, there is no evidence against our null hypothesis of Xgboost since the p-value is 0.8692 and since its p-value are close to the 1, the proportion of our null hypoyhesis is close to the real proportion of Xgboost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95751b6d",
   "metadata": {
    "id": "95751b6d"
   },
   "source": [
    "### 5. Consider the \"Progress Indicators\" data and use \"boolean selection\" with one (or more) of the columns to restrict the data to a subset (of rows) of data and repeat either of the (confidence interval and hypothesis testing) analyses above but this time instead only using this specified subset of countries. - **Haoliang**\n",
    "\n",
    "    - *Potentially relevant subsets of data that might be of interest could be created on the basis of Human Development Index categories, Fragile States Index categories, World Bank economy categories, etc. (e.g., `'fsi_category', 'hdr_hdicode', 'hdr_region', 'wbi_income_group', 'wbi_lending_category', 'wbi_other_(emu_or_hipc)'`, etc.); or, perhaps by alternative boolean selections based on restricting the data to countries with specific continuous variable values that fall within specified thresholds or limits.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aVUCixGUppcf",
   "metadata": {
    "id": "aVUCixGUppcf"
   },
   "source": [
    "### In the 'Boolean selection', we decided to select all countries with the state of fsi_category as 'Warning', and we redo both Confidence Interval and Hypothesis tests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2uOdAYU15wRT",
   "metadata": {
    "id": "2uOdAYU15wRT"
   },
   "source": [
    "### Confidence Interval with 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "obvG5OaJqARB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "obvG5OaJqARB",
    "outputId": "2823a20d-f789-4b22-bd04-24bad30bc1f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.455, 0.504])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition_lst = df_indicators[df_indicators.fsi_category == 'Warning']['iso3']\n",
    "reps = 1000\n",
    "average_error = np.zeros(reps)\n",
    "np.random.seed(123)\n",
    "\n",
    "## For Transfomer\n",
    "for rep in range(reps):\n",
    "    bootstrap_sample = np.random.choice(df_preds[df_preds['iso3'].isin(condition_lst)]['transformer_probability_prediction_error'],\n",
    "                                        size=df_preds[df_preds['iso3'].isin(condition_lst)].shape[0])\n",
    "    average_error[rep] = bootstrap_sample.mean()\n",
    "\n",
    "np.round(np.quantile(average_error, (0.025, 0.975)), 3) # [0.455, 0.504]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "lDyyaYIo5Oz6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lDyyaYIo5Oz6",
    "outputId": "f45b2401-4541-46e1-d191-7612a2e469ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.482, 0.537])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## For Xgboost\n",
    "for rep in range(reps):\n",
    "    bootstrap_sample = np.random.choice(df_preds[df_preds['iso3'].isin(condition_lst)]['xgboost_probability_prediction_error'],\n",
    "                                        size=df_preds[df_preds['iso3'].isin(condition_lst)].shape[0])\n",
    "    average_error[rep] = bootstrap_sample.mean()\n",
    "\n",
    "np.round(np.quantile(average_error, (0.025, 0.975)), 3) # [0.49 , 0.528]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "azXJMUU55dS3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "azXJMUU55dS3",
    "outputId": "244de1fa-5c40-4504-d306-4fa6d177ef59"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.415, 0.443])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## For FFNN\n",
    "for rep in range(reps):\n",
    "    bootstrap_sample = np.random.choice(df_preds[df_preds['iso3'].isin(condition_lst)]['ffnn_probability_prediction_error'],\n",
    "                                        size=df_preds[df_preds['iso3'].isin(condition_lst)].shape[0])\n",
    "    average_error[rep] = bootstrap_sample.mean()\n",
    "\n",
    "np.round(np.quantile(average_error, (0.025, 0.975)), 3) # [0.415 , 0.444]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JH88TW_C5neR",
   "metadata": {
    "id": "JH88TW_C5neR"
   },
   "source": [
    "### Redo the Hypothesis test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "yDJiZmSjdzhC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yDJiZmSjdzhC",
    "outputId": "022ddb09-3852-4582-a7d5-27b9511a4ff8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preds[df_preds['iso3'].isin(condition_lst)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6IHoJxUwqVip",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6IHoJxUwqVip",
    "outputId": "22dcfaf4-2399-4c16-f44a-69bf01968efa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1268"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "condition_lst = df_indicators[df_indicators.fsi_category == 'Warning']['iso3']\n",
    "null = 0.5\n",
    "rep = 10000\n",
    "\n",
    "## For Transfomer\n",
    "observed_test_stat =  \\\n",
    "((df_preds[df_preds['iso3'].isin(condition_lst)]['transformer_classifcation_performance_outcome'] == 'correctly predicted no escalation')\n",
    " | (df_preds[df_preds['iso3'].isin(condition_lst)]['transformer_classifcation_performance_outcome'] == 'correctly predicted escalation')).mean()\n",
    "\n",
    "test_stat = np.zeros(rep)\n",
    "n = df_preds[df_preds['iso3'].isin(condition_lst)].shape[0]\n",
    "for i in range(rep):\n",
    "    sample_mean = sum(np.random.choice(['Correct', 'Incorrect'], size=n) == 'Correct')/n\n",
    "    test_stat[i] = sample_mean\n",
    "\n",
    "sum(abs(test_stat-null) >= abs(observed_test_stat-null)) / rep # p-value=0.1268"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "W2u_vv1g4ovN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W2u_vv1g4ovN",
    "outputId": "8b19428e-fec1-4557-e7a3-1279d2a8c71d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0095"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## For Xgboost\n",
    "np.random.seed(123)\n",
    "observed_test_stat =  \\\n",
    "((df_preds[df_preds['iso3'].isin(condition_lst)]['xgboost_classifcation_performance_outcome'] == 'correctly predicted no escalation')\n",
    " | (df_preds[df_preds['iso3'].isin(condition_lst)]['xgboost_classifcation_performance_outcome'] == 'correctly predicted escalation')).mean()\n",
    "\n",
    "test_stat = np.zeros(rep)\n",
    "n = df_preds[df_preds['iso3'].isin(condition_lst)].shape[0]\n",
    "for i in range(rep):\n",
    "    sample_mean = (np.random.choice(['Correct', 'Incorrect'], size=n) == 'Correct').mean()\n",
    "    test_stat[i] = sample_mean\n",
    "\n",
    "sum(abs(test_stat-null) >= abs(observed_test_stat-null)) / rep # p-value=0.0095"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "T6qtS_QW4qp3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T6qtS_QW4qp3",
    "outputId": "343a8956-d5c6-4efe-98ca-3a7b6f4d8033"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## For FFNN\n",
    "np.random.seed(123)\n",
    "observed_test_stat =  \\\n",
    "((df_preds[df_preds['iso3'].isin(condition_lst)]['ffnn_classifcation_performance_outcome'] == 'correctly predicted no escalation')\n",
    " | (df_preds[df_preds['iso3'].isin(condition_lst)]['ffnn_classifcation_performance_outcome'] == 'correctly predicted escalation')).mean()\n",
    "\n",
    "test_stat = np.zeros(rep)\n",
    "n = df_preds[df_preds['iso3'].isin(condition_lst)].shape[0]\n",
    "for i in range(rep):\n",
    "    sample_mean = sum(np.random.choice(['Correct', 'Incorrect'], size=n) == 'Correct')/n\n",
    "    test_stat[i] = sample_mean\n",
    "\n",
    "sum(abs(test_stat-null) >= abs(observed_test_stat-null)) / rep # p-value=0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "h16kHs-qrOHV",
   "metadata": {
    "id": "h16kHs-qrOHV"
   },
   "source": [
    "### Conclusion:\n",
    "For the average of probability_prediction_error with the country statement as 'Warning'\n",
    "\n",
    "there is a 95% chance that the true parameter falls between 0.455 and 0.504 for Transformer,\n",
    "\n",
    "there is a 95% chance that the true parameter falls between 0.481 and 0.537 for Xgboost,\n",
    "\n",
    "there is a 95% chance that the true parameter falls between 0.415 and 0.444 for FFNN;\n",
    "\n",
    "By comparing the p-value to the table, we conclude that there is strong evidence against our null hypothesis of FFNN since the p-value is 0. There is good evidence against our null hypothesis of Xgboost since the p-value is 0.0095. Still, on the other hand, there is no evidence against our null hypothesis of Transformer since the p-value is 0.1268 and"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dba88e",
   "metadata": {
    "id": "d9dba88e"
   },
   "source": [
    "### 6. (and 7.) Create a two-sample bootstrap confidence interval and perform a hypothesis test comparing the performance of a single model for the data subset created above versus the remaining data not included in that data subset. - **Haoliang**\n",
    "  - A two-sample bootstrap confidence interval is created by repeatedly creating a \"'pair\" of bootstrapped samples\" by making a single bootstrap sample for samples two data subsets individually, and then the other, and then those two \"single sample\" bootstrapped samples together make up the \"'pair\" of bootrapped samples\".\n",
    "  <br><br>\n",
    "    \n",
    "  - A hypothesis test for two (\"unpaired\") samples can be carried out on the basis of permutating shuffling group membership (while ensuring that the original subset sample sizes remain unchanged) in order to create a sampling distribution under a null hypothesis assumption of \"no difference between groups\", or based on `scipy.stats.median_test` which assumes the *medians* of the two groups are identical (or the more powerful `scipy.stats.mannwhitneyu` which again assumes \"no difference between groups\"), or `scipy.stats.ttest_ind` which assumes the *means* of the two groups are identical (and that the samples come from normally distributed populations)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "P0Ri12B-CqY0",
   "metadata": {
    "id": "P0Ri12B-CqY0"
   },
   "source": [
    "### We decided to do the comparison for Transformer,\n",
    "\n",
    "### with $H_0: \\text{There is no difference between those two groups}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ruC5V64kCSfk",
   "metadata": {
    "id": "ruC5V64kCSfk"
   },
   "source": [
    "### For two-sample bootstrapped CI with 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5da1bzXGBzVr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5da1bzXGBzVr",
    "outputId": "b8e80240-c7a3-4c46-9c0b-d93bfa39a526"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.043, 0.103])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "condition_lst = df_indicators[df_indicators.fsi_category == 'Warning']['iso3']\n",
    "reps = 1000\n",
    "\n",
    "average_error_difference = np.zeros(reps)\n",
    "for rep in range(reps):\n",
    "    bootstrap_sample1 = np.random.choice(df_preds[df_preds['iso3'].isin(condition_lst)]['transformer_probability_prediction_error'],\n",
    "                                        size=df_preds['iso3'].isin(condition_lst).shape[0])\n",
    "    bootstrap_sample2 = np.random.choice(df_preds[~df_preds['iso3'].isin(condition_lst)]['transformer_probability_prediction_error'],\n",
    "                                        size=df_preds[~df_preds['iso3'].isin(condition_lst)].shape[0])\n",
    "\n",
    "    average_error_difference[rep] = bootstrap_sample1.mean() - bootstrap_sample2.mean()\n",
    "\n",
    "np.round(np.quantile(average_error_difference, [0.025, 0.975]), 3) # [0.043,  0.103]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9E81kqapOpmU",
   "metadata": {
    "id": "9E81kqapOpmU"
   },
   "source": [
    "### For Null Hypothesis Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dXbZsEcTOu84",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dXbZsEcTOu84",
    "outputId": "93c1c3a1-7d19-4778-d962-23fd5e503d6a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=20182.0, pvalue=0.0002397641612548599)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "stats.mannwhitneyu(df_preds[df_preds['iso3'].isin(condition_lst)]['transformer_probability_prediction_error'],\n",
    "                  df_preds[~df_preds['iso3'].isin(condition_lst)]['transformer_probability_prediction_error']) # p-value=0.00024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "o_BxsSDqPC-S",
   "metadata": {
    "id": "o_BxsSDqPC-S"
   },
   "source": [
    "### Conclusion:\n",
    "For the different average of probability_prediction_error with the country statement as 'Warning' and not 'Warning', there is a 95% chance that the true parameter of the differences between the two  falls between 0.043 and 0.103 for Transformer. Meaning that the transformer model is more accurate for countries that are not in the Warning category.\n",
    "\n",
    "By comparing the p-value to the table, We conclude that there is strong evidence against our null hypothesis since the p-value is 0.00024."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c88707c",
   "metadata": {
    "id": "0c88707c"
   },
   "source": [
    "## \"Paired\" Data\n",
    "\n",
    "The analyses above considered one- and two-sample subsets of data, with samples defined on the basis of specific subsets of data; however, this data utilized above is considered \"unpaired\" since a given *individual* observed outcome is not considered \"twice\" in a \"repeated\" or \"paired\" sort of way with respect to some slightly different conditions. This is no longer the case if we instead compare the result of predictions from two different models on some (sub)set of data; because, since predictions from the two different models are made for the same country, these individual predictions (on the same country) can be natually \"paired\" together.  \n",
    "\n",
    "It turns out that \"paired\" data is naturally more powerful than \"unpaired\" data because it allows us to examine the comparision on the basis of the behavior of the pairs of data, as opposed to a relative comparison between one whole sample versus another whole sample.  To perform a \"paired\" analysis, each individual \"pair\" of data is turned into a single numeric value of the difference (calculated in the same consistent manner across all sets of pairs) between the values of the pair. So for two samples $x$ and $y$ where $x_i$ is \"paired\" with $y_i$, the \"paired\" analysis simply becomes a one-sample anslysis on the basis of $z_i=x_i-y_i$ with a natural null hypothesis assumption that there is no difference on average between the two values comprising the pairs.\n",
    "\n",
    "> Take care to note that paring two samples requires more than just having the same sample size: the pairing must reflect an actual naturally meaningful pair construction justification, such as two prediction made by different models but on the same country.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1e311b",
   "metadata": {
    "id": "4e1e311b"
   },
   "source": [
    "### 8. (and 9.) Create a bootstrap confidence interval and a hypothesis test comparing the performance of two the models across all the data on the basis of a \"paired\" sample analysis (by transforming the paired sample into a single $z_i=x_i-y_i$ difference sample). - **Rithvik**\n",
    "    - A bootstrap confidence interval is created by bootrapping from the sample of \"paired differences\"; whereas, the sampling distribution of the null hypothesis of \"the group an observation belongs to doesn't matter\" can be constructed using a permutation shuffling approach which randomly reassigns the sample membership within each of the paired samples. Functions performing theoretical nonparametric and parametric \"paired\" sample analyses are `scipy.stats.wilcoxon` and `scipy.stats.ttest_rel`, where the null hypothesis of the former assumes the slightly different \"no tendency for one of the samples in the pair to be larger than the other\", while the null hypothesis of the latter assumes \"no difference on average\" between the pairs (and that the samples come from normally distributed populations)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lkBUVQCQ7VV-",
   "metadata": {
    "id": "lkBUVQCQ7VV-"
   },
   "source": [
    "Creating a bootstrap CI 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "JcRv7sOj7av9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JcRv7sOj7av9",
    "outputId": "854da85a-5295-4707-d8de-c8fb50809de1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.052, -0.008])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "reps = 1000\n",
    "bootstrapped_difference_between_two_models = np.zeros(reps)\n",
    "\n",
    "# transformer\n",
    "#sample1 = np.random.choice(df_preds[df_preds['iso3'].isin(condition_lst)]['transformer_probability_prediction_error'],\n",
    "                                        #size=df_preds.shape[0])\n",
    "# xgboost\n",
    "#sample2 = np.random.choice(df_preds[df_preds['iso3'].isin(condition_lst)]['xgboost_probability_prediction_error'],\n",
    "                                        #size=df_preds.shape[0])\n",
    "\n",
    "sample_difference = df_preds[df_preds['iso3'].isin(condition_lst)]['transformer_probability_prediction_error'] - df_preds[df_preds['iso3'].isin(condition_lst)]['xgboost_probability_prediction_error']\n",
    "\n",
    "\n",
    "for rep in range(reps):\n",
    "  bootstrap_sample = np.random.choice(sample_difference, size=df_preds['iso3'].isin(condition_lst).shape[0])\n",
    "  bootstrapped_difference_between_two_models[rep] = bootstrap_sample.mean()\n",
    "\n",
    "np.round(np.quantile(bootstrapped_difference_between_two_models, [0.025, 0.975]), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "O5OTJpaDAE71",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O5OTJpaDAE71",
    "outputId": "8458a13a-e25e-4afe-897f-f154f7c84558"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=12627.0, pvalue=0.029258109837566448)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.mannwhitneyu(df_preds[df_preds['iso3'].isin(condition_lst)]['transformer_probability_prediction_error'],\n",
    "                   df_preds[df_preds['iso3'].isin(condition_lst)]['xgboost_probability_prediction_error']) #pvalue [0.029]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98290690",
   "metadata": {
    "id": "98290690"
   },
   "source": [
    "\n",
    "### 10. Repeat the above analyses for different model pairs on some different subsets of data. - **Alex**\n",
    "\n",
    "    - **Ideally, you will use this exercise to identify different subsets of the data where there's demonstrable statistical evidence that the different predictive models have differential performance levels. These would then be provide different characterizations on the basis of the \"Progress Indicators\" data as to differential performance between the different (`xgboost`, `ffnn`, and `transformer`) predictive models. Finding such potential explanations for differential predictive model performance has the potential to form the basis of your final project slides and presentation, and can help make completing your project a relatively straightfoward task that essentially only requires subsequent reanalysis using a linear regression model and chracterizations elaborating on the findings you've already made based on this analysis here.**\n",
    "\n",
    "    > *Potentially relevant subsets of data that might be of interest could be created on the basis of Human Development Index categories, Fragile States Index categories, World Bank economy categories, etc. (e.g., `'fsi_category', 'hdr_hdicode', 'hdr_region', 'wbi_income_group', 'wbi_lending_category', 'wbi_other_(emu_or_hipc)'`, etc.); or, perhaps by alternative boolean selections based on restricting the data to countries with specific continuous variable values that fall within specified thresholds or limits.*\n",
    "\n",
    "    - For the purposes of **Project Assignment #1** it's not mandatory that your project team has managed to produce statistical evidence suggestive of differences in the performance of the three models (`xgboost`, `ffnn`, and `transformer`) within different country subsets; however, you will need to do so in order to adequately complete **Project Assignment #2** which is due on Nov 13 (the Monday after you return from Reading Week), so hopefully you'll be able to make some progress towards this task through your work and submission for **Project Assignment #1**.\n",
    "    \n",
    "        > A reasonable approach to identifying model performances differences within different country subsets is to first explore model performance **matrics** in the manner of the Oct 13 **Project Tutorial Activity and Assignment**, and then subsequently apply confidence interval and/or hypothesis testing methodologies in terms of the Prediction Probability \"Error\" or Prediciton Classification \"Correctness\" outcomes considered here in **Project Assignment #1** in order to provide statistical evidence of any observed model performance differences within those identified country subsets.\n",
    "        \n",
    "\n",
    "- Make sure the sequence of analyses that you perform are clear and understandable. E.g., what model(s) data are used, and for what data subset(s)?\n",
    "    - **Your mark for the Tutorial Assignment will be based on completing the items below and the clarity and correctness of your work.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f203b0",
   "metadata": {},
   "source": [
    "# THIS IS THE CODE TO FIND LOWEST P_VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11726427",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#TRANSFORMER\n",
    "df_merged['transformer_probability_prediction_error'] = np.abs(df_preds['y_true_transformer'].astype(float) - df_preds['y_pred_proba_transformer'])\n",
    "\n",
    "#XGboost\n",
    "df_merged['xgboost_probability_prediction_error'] = np.abs(df_preds['y_true_xgboost'].astype(float) - df_preds['y_pred_proba_xgboost'])\n",
    "\n",
    "#ffnn\n",
    "df_merged['ffnn_probability_prediction_error'] = np.abs(df_preds['y_true_ffnn'].astype(float) - df_preds['y_pred_proba_ffnn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c99dcaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_copy = df_merged.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0125d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yearmonth                                                                                                                  0\n",
      "sowc_women-s-economic-empowerment__unemployment-rate-2010-2020-r_male_rural                                                0\n",
      "sowc_women-s-economic-empowerment__labour-force-participation-rate-2010-2020-r_female_total                                0\n",
      "sowc_women-s-economic-empowerment__labour-force-participation-rate-2010-2020-r_female_urban                                0\n",
      "sowc_women-s-economic-empowerment__labour-force-participation-rate-2010-2020-r_female_rural                                0\n",
      "                                                                                                                        ... \n",
      "sowc_children-with-disabilities__education_foundational-learning-skills-2017-2021-r_children-without-disabilities        316\n",
      "sowc_hiv-aids-intervention-coverage__condom-use-among-adolescents-age-15-19-with-multiple-partners-2012-2020-r_female    316\n",
      "sowc_women-s-economic-empowerment__time-use-2013-2020-r_female_female                                                    323\n",
      "sowc_women-s-economic-empowerment__time-use-2013-2020-r_female_male                                                      323\n",
      "sowc_child-protection__sexual-violence-in-childhood-2013-2020-r_attitudes_male_female                                    337\n",
      "Length: 1346, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_merged_copy.isnull().sum().sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06fe5aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yearmonth</th>\n",
       "      <th>fips</th>\n",
       "      <th>y_pred_transformer</th>\n",
       "      <th>y_pred_proba_transformer</th>\n",
       "      <th>y_true_transformer</th>\n",
       "      <th>y_pred_xgboost</th>\n",
       "      <th>y_pred_proba_xgboost</th>\n",
       "      <th>y_true_xgboost</th>\n",
       "      <th>y_pred_ffnn</th>\n",
       "      <th>y_pred_proba_ffnn</th>\n",
       "      <th>...</th>\n",
       "      <th>fsi_p1:_state_legitimacy</th>\n",
       "      <th>fsi_p2:_public_services</th>\n",
       "      <th>fsi_p3:_human_rights</th>\n",
       "      <th>fsi_c1:_security_apparatus</th>\n",
       "      <th>fsi_c2:_factionalized_elites</th>\n",
       "      <th>fsi_x1:_external_intervention</th>\n",
       "      <th>fsi_category</th>\n",
       "      <th>transformer_probability_prediction_error</th>\n",
       "      <th>xgboost_probability_prediction_error</th>\n",
       "      <th>ffnn_probability_prediction_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202211</td>\n",
       "      <td>FJ</td>\n",
       "      <td>False</td>\n",
       "      <td>0.183897</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.066500</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.409958</td>\n",
       "      <td>...</td>\n",
       "      <td>6.1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>5.4</td>\n",
       "      <td>6.4</td>\n",
       "      <td>8.2</td>\n",
       "      <td>6.6</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.183897</td>\n",
       "      <td>0.066500</td>\n",
       "      <td>0.409958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202212</td>\n",
       "      <td>FJ</td>\n",
       "      <td>False</td>\n",
       "      <td>0.267831</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.099643</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.406696</td>\n",
       "      <td>...</td>\n",
       "      <td>6.1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>5.4</td>\n",
       "      <td>6.4</td>\n",
       "      <td>8.2</td>\n",
       "      <td>6.6</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.267831</td>\n",
       "      <td>0.099643</td>\n",
       "      <td>0.406696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202211</td>\n",
       "      <td>TZ</td>\n",
       "      <td>False</td>\n",
       "      <td>0.482585</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.704086</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.545236</td>\n",
       "      <td>...</td>\n",
       "      <td>6.9</td>\n",
       "      <td>8.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>4.6</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.482585</td>\n",
       "      <td>0.295914</td>\n",
       "      <td>0.545236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202212</td>\n",
       "      <td>TZ</td>\n",
       "      <td>False</td>\n",
       "      <td>0.187792</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.638444</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.534560</td>\n",
       "      <td>...</td>\n",
       "      <td>6.9</td>\n",
       "      <td>8.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>4.6</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.187792</td>\n",
       "      <td>0.361556</td>\n",
       "      <td>0.534560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202301</td>\n",
       "      <td>TZ</td>\n",
       "      <td>True</td>\n",
       "      <td>0.539319</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.608380</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.538583</td>\n",
       "      <td>...</td>\n",
       "      <td>6.9</td>\n",
       "      <td>8.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>4.6</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.460681</td>\n",
       "      <td>0.608380</td>\n",
       "      <td>0.461417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>202211</td>\n",
       "      <td>MJ</td>\n",
       "      <td>False</td>\n",
       "      <td>0.182196</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.079453</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.291874</td>\n",
       "      <td>...</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.3</td>\n",
       "      <td>Stable</td>\n",
       "      <td>0.182196</td>\n",
       "      <td>0.079453</td>\n",
       "      <td>0.291874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>202212</td>\n",
       "      <td>MJ</td>\n",
       "      <td>False</td>\n",
       "      <td>0.203236</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.060189</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.300321</td>\n",
       "      <td>...</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.3</td>\n",
       "      <td>Stable</td>\n",
       "      <td>0.203236</td>\n",
       "      <td>0.060189</td>\n",
       "      <td>0.300321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>202211</td>\n",
       "      <td>TD</td>\n",
       "      <td>True</td>\n",
       "      <td>0.527107</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.697625</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.335496</td>\n",
       "      <td>...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>7.3</td>\n",
       "      <td>5.6</td>\n",
       "      <td>3.3</td>\n",
       "      <td>Stable</td>\n",
       "      <td>0.527107</td>\n",
       "      <td>0.302375</td>\n",
       "      <td>0.335496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>202212</td>\n",
       "      <td>TD</td>\n",
       "      <td>True</td>\n",
       "      <td>0.555677</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.729246</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.324000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>7.3</td>\n",
       "      <td>5.6</td>\n",
       "      <td>3.3</td>\n",
       "      <td>Stable</td>\n",
       "      <td>0.555677</td>\n",
       "      <td>0.729246</td>\n",
       "      <td>0.324000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>202301</td>\n",
       "      <td>TD</td>\n",
       "      <td>True</td>\n",
       "      <td>0.565700</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.591722</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.332455</td>\n",
       "      <td>...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>7.3</td>\n",
       "      <td>5.6</td>\n",
       "      <td>3.3</td>\n",
       "      <td>Stable</td>\n",
       "      <td>0.434300</td>\n",
       "      <td>0.591722</td>\n",
       "      <td>0.667545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>364 rows × 1346 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     yearmonth fips  y_pred_transformer  y_pred_proba_transformer  \\\n",
       "0       202211   FJ               False                  0.183897   \n",
       "1       202212   FJ               False                  0.267831   \n",
       "2       202211   TZ               False                  0.482585   \n",
       "3       202212   TZ               False                  0.187792   \n",
       "4       202301   TZ                True                  0.539319   \n",
       "..         ...  ...                 ...                       ...   \n",
       "359     202211   MJ               False                  0.182196   \n",
       "360     202212   MJ               False                  0.203236   \n",
       "361     202211   TD                True                  0.527107   \n",
       "362     202212   TD                True                  0.555677   \n",
       "363     202301   TD                True                  0.565700   \n",
       "\n",
       "     y_true_transformer  y_pred_xgboost  y_pred_proba_xgboost  y_true_xgboost  \\\n",
       "0                 False           False              0.066500           False   \n",
       "1                 False           False              0.099643           False   \n",
       "2                 False            True              0.704086            True   \n",
       "3                 False            True              0.638444            True   \n",
       "4                  True            True              0.608380           False   \n",
       "..                  ...             ...                   ...             ...   \n",
       "359               False           False              0.079453           False   \n",
       "360               False           False              0.060189           False   \n",
       "361               False            True              0.697625            True   \n",
       "362               False            True              0.729246           False   \n",
       "363                True            True              0.591722           False   \n",
       "\n",
       "     y_pred_ffnn  y_pred_proba_ffnn  ...  fsi_p1:_state_legitimacy  \\\n",
       "0          False           0.409958  ...                       6.1   \n",
       "1          False           0.406696  ...                       6.1   \n",
       "2           True           0.545236  ...                       6.9   \n",
       "3           True           0.534560  ...                       6.9   \n",
       "4           True           0.538583  ...                       6.9   \n",
       "..           ...                ...  ...                       ...   \n",
       "359        False           0.291874  ...                       3.9   \n",
       "360        False           0.300321  ...                       3.9   \n",
       "361        False           0.335496  ...                       3.5   \n",
       "362        False           0.324000  ...                       3.5   \n",
       "363        False           0.332455  ...                       3.5   \n",
       "\n",
       "    fsi_p2:_public_services  fsi_p3:_human_rights  fsi_c1:_security_apparatus  \\\n",
       "0                       4.2                   5.4                         6.4   \n",
       "1                       4.2                   5.4                         6.4   \n",
       "2                       8.4                   5.6                         4.6   \n",
       "3                       8.4                   5.6                         4.6   \n",
       "4                       8.4                   5.6                         4.6   \n",
       "..                      ...                   ...                         ...   \n",
       "359                     3.8                   2.9                         4.0   \n",
       "360                     3.8                   2.9                         4.0   \n",
       "361                     4.3                   3.5                         7.3   \n",
       "362                     4.3                   3.5                         7.3   \n",
       "363                     4.3                   3.5                         7.3   \n",
       "\n",
       "     fsi_c2:_factionalized_elites  fsi_x1:_external_intervention  \\\n",
       "0                             8.2                            6.6   \n",
       "1                             8.2                            6.6   \n",
       "2                             6.5                            6.0   \n",
       "3                             6.5                            6.0   \n",
       "4                             6.5                            6.0   \n",
       "..                            ...                            ...   \n",
       "359                           6.5                            6.3   \n",
       "360                           6.5                            6.3   \n",
       "361                           5.6                            3.3   \n",
       "362                           5.6                            3.3   \n",
       "363                           5.6                            3.3   \n",
       "\n",
       "     fsi_category  transformer_probability_prediction_error  \\\n",
       "0         Warning                                  0.183897   \n",
       "1         Warning                                  0.267831   \n",
       "2         Warning                                  0.482585   \n",
       "3         Warning                                  0.187792   \n",
       "4         Warning                                  0.460681   \n",
       "..            ...                                       ...   \n",
       "359        Stable                                  0.182196   \n",
       "360        Stable                                  0.203236   \n",
       "361        Stable                                  0.527107   \n",
       "362        Stable                                  0.555677   \n",
       "363        Stable                                  0.434300   \n",
       "\n",
       "     xgboost_probability_prediction_error  ffnn_probability_prediction_error  \n",
       "0                                0.066500                           0.409958  \n",
       "1                                0.099643                           0.406696  \n",
       "2                                0.295914                           0.545236  \n",
       "3                                0.361556                           0.534560  \n",
       "4                                0.608380                           0.461417  \n",
       "..                                    ...                                ...  \n",
       "359                              0.079453                           0.291874  \n",
       "360                              0.060189                           0.300321  \n",
       "361                              0.302375                           0.335496  \n",
       "362                              0.729246                           0.324000  \n",
       "363                              0.591722                           0.667545  \n",
       "\n",
       "[364 rows x 1346 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc099dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      9.5\n",
       "1      9.5\n",
       "2      8.1\n",
       "3      NaN\n",
       "4      1.5\n",
       "      ... \n",
       "213    NaN\n",
       "214    NaN\n",
       "215    NaN\n",
       "216    NaN\n",
       "217    NaN\n",
       "Name: sowc_women-s-economic-empowerment__unemployment-rate-2010-2020-r_male_rural, Length: 218, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_indicators['sowc_women-s-economic-empowerment__unemployment-rate-2010-2020-r_male_rural']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e11e408",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2.2\n",
       "1       2.2\n",
       "2       0.5\n",
       "3       0.5\n",
       "4       0.5\n",
       "       ... \n",
       "359    12.6\n",
       "360    12.6\n",
       "361     2.7\n",
       "362     2.7\n",
       "363     2.7\n",
       "Name: sowc_women-s-economic-empowerment__unemployment-rate-2010-2020-r_male_rural, Length: 364, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged['sowc_women-s-economic-empowerment__unemployment-rate-2010-2020-r_male_rural']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6246727c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['yearmonth', 'fips', 'y_pred_transformer', 'y_pred_proba_transformer',\n",
       "       'y_true_transformer', 'y_pred_xgboost', 'y_pred_proba_xgboost',\n",
       "       'y_true_xgboost', 'y_pred_ffnn', 'y_pred_proba_ffnn',\n",
       "       ...\n",
       "       'fsi_p1:_state_legitimacy', 'fsi_p2:_public_services',\n",
       "       'fsi_p3:_human_rights', 'fsi_c1:_security_apparatus',\n",
       "       'fsi_c2:_factionalized_elites', 'fsi_x1:_external_intervention',\n",
       "       'fsi_category', 'transformer_probability_prediction_error',\n",
       "       'xgboost_probability_prediction_error',\n",
       "       'ffnn_probability_prediction_error'],\n",
       "      dtype='object', length=115)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged_copy.columns[df_merged.isnull().sum()<5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c5c98d99",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "df_of_pvalues = pd.DataFrame({\n",
    "    'i': [],\n",
    "    'T_x': [],\n",
    "    'T_f': [],\n",
    "    'x_f': []\n",
    "})\n",
    "\n",
    "list_of_pvalue_T_x = np.zeros(1343-14)\n",
    "list_of_pvalue_T_f = np.zeros(1343-14)\n",
    "list_of_pvalue_x_f = np.zeros(1343-14)\n",
    "\n",
    "for i in range(14,1343):\n",
    "    col = df_merged.iloc[:,i]\n",
    "    if is_numeric_dtype(col):\n",
    "        adjustable_condition_lst = df_merged[col>col.mean()]\n",
    "        if adjustable_condition_lst.shape[0]>0:\n",
    "            a = stats.mannwhitneyu(adjustable_condition_lst['transformer_probability_prediction_error'], adjustable_condition_lst['xgboost_probability_prediction_error'])[1]\n",
    "            b = stats.mannwhitneyu(adjustable_condition_lst['transformer_probability_prediction_error'], adjustable_condition_lst['ffnn_probability_prediction_error'])[1] \n",
    "            c = stats.mannwhitneyu(adjustable_condition_lst['xgboost_probability_prediction_error'], adjustable_condition_lst['ffnn_probability_prediction_error'])[1]\n",
    "            df_of_pvalues.loc[len(df_of_pvalues.index)] = [i, a, b, c] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e56e8851",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>T_x</th>\n",
       "      <th>T_f</th>\n",
       "      <th>x_f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>185.0</td>\n",
       "      <td>0.513702</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>9.174826e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>53.0</td>\n",
       "      <td>0.069332</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>3.187419e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>174.0</td>\n",
       "      <td>0.172071</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>1.454253e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>176.0</td>\n",
       "      <td>0.483509</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>1.076825e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>173.0</td>\n",
       "      <td>0.114437</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>1.441254e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>186.0</td>\n",
       "      <td>0.237348</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>1.172135e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>175.0</td>\n",
       "      <td>0.349926</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>8.717458e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>89.0</td>\n",
       "      <td>0.042853</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>5.311670e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>1332.0</td>\n",
       "      <td>0.136779</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>6.744786e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>124.0</td>\n",
       "      <td>0.453756</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>9.141477e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           i       T_x       T_f           x_f\n",
       "171    185.0  0.513702  0.000002  9.174826e-06\n",
       "39      53.0  0.069332  0.000009  3.187419e-08\n",
       "160    174.0  0.172071  0.000013  1.454253e-06\n",
       "162    176.0  0.483509  0.000014  1.076825e-05\n",
       "159    173.0  0.114437  0.000017  1.441254e-06\n",
       "172    186.0  0.237348  0.000038  1.172135e-05\n",
       "161    175.0  0.349926  0.000050  8.717458e-06\n",
       "75      89.0  0.042853  0.000064  5.311670e-07\n",
       "1311  1332.0  0.136779  0.000067  6.744786e-07\n",
       "110    124.0  0.453756  0.000068  9.141477e-05"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is to see the list of the smallest values.\n",
    "df_of_pvalues.nsmallest(10, 'T_f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7cd40eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       NaN\n",
       "1       NaN\n",
       "2      55.1\n",
       "3      55.1\n",
       "4      55.1\n",
       "       ... \n",
       "359    32.9\n",
       "360    32.9\n",
       "361    58.2\n",
       "362    58.2\n",
       "363    58.2\n",
       "Name: sowc_maternal-and-newborn-health__demand-for-family-planning-satisfied-with-modern-methods-2016-2021-r_service-coverage-sub-index-on-reproductive-maternal-newborn-and-child-health, Length: 364, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is to figure out the name of the column\n",
    "df_merged.iloc[:, 53]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b762d332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06933238064166371 9.004449636736636e-06 3.187418666551089e-08\n"
     ]
    }
   ],
   "source": [
    "#this is just to double check the results\n",
    "col = df_merged.iloc[:,53]\n",
    "adjustable_condition_lst = df_merged[col>col.mean()]\n",
    "a = stats.mannwhitneyu(adjustable_condition_lst['transformer_probability_prediction_error'], adjustable_condition_lst['xgboost_probability_prediction_error'])[1]\n",
    "b = stats.mannwhitneyu(adjustable_condition_lst['transformer_probability_prediction_error'], adjustable_condition_lst['ffnn_probability_prediction_error'])[1] \n",
    "c = stats.mannwhitneyu(adjustable_condition_lst['xgboost_probability_prediction_error'], adjustable_condition_lst['ffnn_probability_prediction_error'])[1]\n",
    "\n",
    "print(a,b,c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cf3511",
   "metadata": {},
   "source": [
    "# ENDS HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "Ln8UKtKq14qE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ln8UKtKq14qE",
    "outputId": "771eaaac-e4c2-4907-b016-46b4479caea0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer, xgboost: [-0.069 -0.023], MannwhitneyuResult(statistic=5524.0, pvalue=0.018547054580071977)\n",
      "Transformer, ffnn: [-0.035  0.   ], MannwhitneyuResult(statistic=6405.0, pvalue=0.5280832419362722)\n",
      "xgboost, ffnn: [0.009 0.047], MannwhitneyuResult(statistic=7849.0, pvalue=0.028369999800106408)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "reps = 500\n",
    "#changable_condition_lst = df_indicators[~(df_indicators.wbi_lending_category == 'IBRD') | ~(df_indicators.wbi_lending_category == 'IDA')]['iso3']\n",
    "changable_condition_lst = df_indicators[df_indicators['sowc_education__equitable-access_out-of-school-rate-2013-2022-r_upper-secondary-education_male']>28.156608703703704]['iso3']\n",
    "\n",
    "\n",
    "bootstrapped_difference_between_transformer_xgboost = np.zeros(reps)\n",
    "bootstrapped_difference_between_transformer_ffnn = np.zeros(reps)\n",
    "bootstrapped_difference_between_xgboost_ffnn = np.zeros(reps)\n",
    "\n",
    "sample_difference_transformer_xgboost = df_preds[df_preds['iso3'].isin(changable_condition_lst)]['transformer_probability_prediction_error'] - \\\n",
    "                                                      df_preds[df_preds['iso3'].isin(changable_condition_lst)]['xgboost_probability_prediction_error']\n",
    "\n",
    "sample_difference_transformer_ffnn = df_preds[df_preds['iso3'].isin(changable_condition_lst)]['transformer_probability_prediction_error'] - \\\n",
    "                                                      df_preds[df_preds['iso3'].isin(changable_condition_lst)]['ffnn_probability_prediction_error']\n",
    "\n",
    "sample_difference_xgboost_ffnn = df_preds[df_preds['iso3'].isin(changable_condition_lst)]['xgboost_probability_prediction_error'] - \\\n",
    "                                                      df_preds[df_preds['iso3'].isin(changable_condition_lst)]['ffnn_probability_prediction_error']\n",
    "\n",
    "for rep in range(reps):\n",
    "  bootstrapped_difference_between_transformer_xgboost[rep] = np.random.choice(sample_difference_transformer_xgboost,\n",
    "                                                                              size=df_preds['iso3'].isin(changable_condition_lst).shape[0]).mean()\n",
    "  bootstrapped_difference_between_transformer_ffnn[rep] = np.random.choice(sample_difference_transformer_ffnn,\n",
    "                                                                           size=df_preds['iso3'].isin(changable_condition_lst).shape[0]).mean()\n",
    "  bootstrapped_difference_between_xgboost_ffnn[rep] = np.random.choice(sample_difference_xgboost_ffnn,\n",
    "                                                                       size=df_preds['iso3'].isin(changable_condition_lst).shape[0]).mean()\n",
    "\n",
    "transformer_xgboost_CI = np.round(np.quantile(bootstrapped_difference_between_transformer_xgboost, [0.025, 0.975]), 3)\n",
    "transformer_ffnn_CI = np.round(np.quantile(bootstrapped_difference_between_transformer_ffnn, [0.025, 0.975]), 3)\n",
    "xgboost_ffnn_CI = np.round(np.quantile(bootstrapped_difference_between_xgboost_ffnn, [0.025, 0.975]), 3)\n",
    "\n",
    "transformer_xgboost_HT =stats.mannwhitneyu(df_preds[df_preds['iso3'].isin(changable_condition_lst)]['transformer_probability_prediction_error'],\n",
    "                                           df_preds[df_preds['iso3'].isin(changable_condition_lst)]['xgboost_probability_prediction_error'])\n",
    "\n",
    "transformer_ffnn_HI =stats.mannwhitneyu(df_preds[df_preds['iso3'].isin(changable_condition_lst)]['transformer_probability_prediction_error'],\n",
    "                                        df_preds[df_preds['iso3'].isin(changable_condition_lst)]['ffnn_probability_prediction_error'])\n",
    "\n",
    "xgboost_ffnn_HI =stats.mannwhitneyu(df_preds[df_preds['iso3'].isin(changable_condition_lst)]['xgboost_probability_prediction_error'],\n",
    "                                    df_preds[df_preds['iso3'].isin(changable_condition_lst)]['ffnn_probability_prediction_error'])\n",
    "\n",
    "\n",
    "print(f\"Transformer, xgboost: {transformer_xgboost_CI}, {transformer_xgboost_HT}\")\n",
    "print(f\"Transformer, ffnn: {transformer_ffnn_CI}, {transformer_ffnn_HI}\")\n",
    "print(f\"xgboost, ffnn: {xgboost_ffnn_CI}, {xgboost_ffnn_HI}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
